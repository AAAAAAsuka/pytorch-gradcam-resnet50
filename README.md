Usage: `python grad-cam.py --image-path <path_to_image>`

To use with CUDA:
`python grad-cam.py --image-path <path_to_image> --use-cuda`


这个上面的懂点英文都应该看得懂怎么用，我这个只不过把原始的vgg19网络改成了imagenet预训练的resnet50而已，实际上对于任意的处理图片的还是可以用的，但是我们是做视频的，就搞得很麻烦，因为网络多一维时间维，搞得我很头痛。因此虽然改出来了这个东西但是并没有什么成就感，放出来给各位想用resnet50网络来测试cam图的各位用吧。


## 注意

上面默认的image_path已经是./examples了


[原始链接](https://github.com/jacobgil/pytorch-grad-cam)


虽然看的还是英文，但是什么时候中文才能普及全球呢.....


## 后续说明
这两天研究了一下发现这个cam也就是单纯一个提取特征之后把features结合到我们的原图上，实际上如果不是研究很细致的话不需要了解原理。因为中间一系列的数学过程其实就是提特征，完事我们再把这个特征和原图组合起来。说一千道一万其实我们只要能在网络中先提取特征，再把特征保存下来，之后自己用opencv拼合特征图和原图也是可以做到的。（目前这个路子应该是很传统，比较笨，但是也是很简单能实现。）
后续要是有时间再研究的话可能会这么更新一下，不过我感觉这个工作做到这儿也就到头了，毕竟视频帧的可视化我们直接在自己大工程中任意处找准位置就可以输出的，不需要搞得这么麻烦。
目前可以证实第一段的做法从理论上讲没有问题，通过本地之前的工程验证过运用本工程的show_cam_on_image与用opencv拼接两张图而言，两个图打印效果是不差的。（opencv参数可能需要微调，这个根据个人情况因人而异）如果确实想按照2d这种思路做确实有可能由于自己设置网络的时候由于时间维度的偏差会导致映射效果不好之类的。（因为一般我们数据预处理的时候要求的视频帧一定是有代表性的，所以帧与帧之间肯定保证人用肉眼也可以看的出来。）
## 思路流程
1. 首先先解决提取特征的问题，这个其实基于现有的框架的内置函数比较好做，而且一般提取的特征我们主要从conv层后面进行筛选。对于3d的network确实因为时间维度存在，一开始对于这里提取特征会存在困惑。但是简单想一下实际上只要把时间维上每一个存的图片拿出来然后打出对应每张图过完conv的特征也是可以做到的。
2. 提取好特征想做出这种拼合的效果可以做的方法有很多，这个我上面也有提到，如果继续套用本工程的话确实后面可能会出现对应的特征无法映射到原图的问题。这里确实需要我们人眼来观察最后将得到的特征分布映射到关键帧上。（也就是说我们可以先把feature存下，再将得到的feature一一映射会每个关键帧，用肉眼选取效果最好的一个，也未尝不是一种做法。）
## 总结
确实是对于视频帧处理的话需要考虑到最后有关不同维度梯度时会出现问题。不过cam还是可以按照本工程对应的代码段把特征做出来的，之后按照我们之前讲的拼接方法将对应的cam图和origin clips结合即可。